{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch\n",
    "\n",
    "form [知乎]<https://zhuanlan.zhihu.com/p/25572330>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100+ Tensor的操作，包括换位、索引、切片、数学运算、线性算法和随机数等等。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "result1: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "result2: tensor([[1.6384, 0.7291, 1.3543],\n",
      "        [0.5256, 1.7762, 0.8310],\n",
      "        [0.6966, 1.3659, 1.3310],\n",
      "        [1.8738, 0.6087, 1.4210],\n",
      "        [0.8028, 0.8299, 1.6481]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0224, 0.9936, 0.9853, 0.1030, 0.3492])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.Tensor(5, 3)  # 构造一个未初始化的5*3的矩阵\n",
    "x = torch.rand(5, 3)  # 构造一个随机初始化的矩阵\n",
    "x # 此处在notebook中输出x的值来查看具体的x内容\n",
    "print(x.size()) \n",
    "\n",
    "#NOTE: torch.Size 事实上是一个tuple, 所以其支持相关的操作*\n",
    "y = torch.rand(5, 3)\n",
    "\n",
    "#此处 将两个同形矩阵相加有两种语法结构\n",
    "x + y # 语法一\n",
    "torch.add(x, y) # 语法二\n",
    "\n",
    "# 另外输出tensor也有两种写法\n",
    "result = torch.Tensor(5, 3) # 语法一\n",
    "print(\"result1:\",result)\n",
    "torch.add(x, y, out=result) # 语法二\n",
    "print(\"result2:\",result)\n",
    "y.add_(x) # 将y与x相加\n",
    "\n",
    "# 特别注明：任何可以改变tensor内容的操作都会在方法名后加一个下划线'_'\n",
    "# 例如：x.copy_(y), x.t_(), 这俩都会改变x的值。\n",
    "\n",
    "#另外python中的切片操作也是资次的。\n",
    "x[:,1] #这一操作会输出x矩阵的第二列的所有值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy桥\n",
    "\n",
    "将Torch的Tensor和numpy的array相互转换简直就是洒洒水啦。注意Torch的Tensor和numpy的array会共享他们的存储空间，修改一个会导致另外的一个也被修改。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]], device='mps:0', grad_fn=<AddBackward0>)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], device='mps:0', grad_fn=<ToCopyBackward0>)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], device='mps:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 此处演示tensor和numpy数据结构的相互转换\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "\n",
    "\n",
    "device = torch.device('mps')\n",
    "# 此处演示当修改numpy数组之后,与之相关联的tensor也会相应的被修改\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# 将numpy的Array转换为torch的Tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# 另外除了CharTensor之外，所有的tensor都可以在CPU运算和GPU预算之间相互转换\n",
    "# 使用CUDA函数来将Tensor移动到GPU上\n",
    "# 当CUDA可用时会进行GPU的运算\n",
    "# if torch.mps.is_available():\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "print(x + y)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2, 2), requires_grad = True)\n",
    "# print(x)\n",
    "y = x + 2\n",
    "# print(y)\n",
    "# y.creator\n",
    "y.grad_fn\n",
    "\n",
    "# y 是作为一个操作的结果创建的因此y有一个creator \n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "# 现在我们来使用反向传播\n",
    "out.backward()\n",
    "\n",
    "# out.backward()和操作out.backward(torch.Tensor([1.0]))是等价的\n",
    "# 在此处输出 d(out)/dx\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.1200e+01, 5.1200e+01, 5.1200e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad = True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "gradients = torch.FloatTensor([0.1, 0.1, 0.0001])\n",
    "y.backward(gradients)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 =  nn.Conv2d(1,6,5) # 1 input image channel, 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) # an affine operation: y = Wx + b\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))# Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # If the size is a square you can only specify a single number\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size  = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment  \\\n",
       "0      1956967341       empty   \n",
       "1      1956967666     sadness   \n",
       "2      1956967696     sadness   \n",
       "3      1956967789  enthusiasm   \n",
       "4      1956968416     neutral   \n",
       "...           ...         ...   \n",
       "39995  1753918954     neutral   \n",
       "39996  1753919001        love   \n",
       "39997  1753919005        love   \n",
       "39998  1753919043   happiness   \n",
       "39999  1753919049        love   \n",
       "\n",
       "                                                 content  \n",
       "0      @tiffanylue i know  i was listenin to bad habi...  \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                    Funeral ceremony...gloomy friday...  \n",
       "3                   wants to hang out with friends SOON!  \n",
       "4      @dannycastillo We want to trade with someone w...  \n",
       "...                                                  ...  \n",
       "39995                                   @JohnLloydTaylor  \n",
       "39996                     Happy Mothers Day  All my love  \n",
       "39997  Happy Mother's Day to all the mommies out ther...  \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./datasets/tweet_emotions.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch\n",
    "\n",
    "form [知乎]<https://zhuanlan.zhihu.com/p/25572330>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "320a91abf0f16130e6526b9f7a206aa4e8166a1871a42ed6e22aa83b94f8a610"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('misinfo': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
